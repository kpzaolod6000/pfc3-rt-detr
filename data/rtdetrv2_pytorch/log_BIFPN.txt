Initialized distributed mode...
cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': None, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': None, 'tuning': 'rtdetrv2_r18vd_120e_coco_rerun_48.1.pth', 'epoches': 10, 'last_epoch': -1, 'use_amp': True, 'use_ema': True, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.1, 'find_unused_parameters': False, 'seed': 0, 'print_freq': 100, 'checkpoint_freq': 1, 'output_dir': './output/rtdetrv2_r18vd_120e_coco', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 1, 'remap_mscoco_category': True, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/home/pytorch/data/rtdetrv2_pytorch/configs/dataset/coco/train2017/', 'ann_file': '/home/pytorch/data/rtdetrv2_pytorch/configs/dataset/coco/annotations/instances_train2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 117, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': None, 'stop_epoch': 71}, 'total_batch_size': 4}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/home/pytorch/data/rtdetrv2_pytorch/configs/dataset/coco/val2017/', 'ann_file': '/home/pytorch/data/rtdetrv2_pytorch/configs/dataset/coco/annotations/instances_val2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 4}, 'print_freq': 100, 'output_dir': './output/rtdetrv2_r18vd_120e_coco', 'checkpoint_freq': 1, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': True, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': True, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'epoches': 10, 'clip_max_norm': 0.1, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*(?:norm|bn)).*$', 'weight_decay': 0.0}], 'lr': 0.0001, 'betas': [0.9, 0.999], 'weight_decay': 0.0001}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [1000], 'gamma': 0.1}, 'lr_warmup_scheduler': {'type': 'LinearWarmup', 'warmup_duration': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 18, 'variant': 'd', 'freeze_at': -1, 'return_idx': [0, 1, 2, 3], 'num_stages': 4, 'freeze_norm': False, 'pretrained': True}, 'HybridEncoder': {'in_channels': [64, 128, 256, 512], 'feat_strides': [4, 8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [3], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 0.5, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256, 256], 'feat_strides': [4, 8, 16, 32], 'hidden_dim': 256, 'num_levels': 4, 'num_layers': 3, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1, 'num_points': [4, 4, 4, 4], 'cross_attn_method': 'default', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['../dataset/coco_detection.yml', '../runtime.yml', './include/dataloader.yml', './include/optimizer.yml', './include/rtdetrv2_r50vd.yml'], 'config': 'configs/rtdetrv2/rtdetrv2_r18vd_120e_coco.yml', 'tuning': 'rtdetrv2_r18vd_120e_coco_rerun_48.1.pth', 'seed': 0, 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}
Start training
Load PResNet18 state_dict
tuning checkpoint from rtdetrv2_r18vd_120e_coco_rerun_48.1.pth
Load model.state_dict, {'missed': ['decoder.input_proj.3.conv.weight', 'decoder.input_proj.3.norm.weight', 'decoder.input_proj.3.norm.bias', 'decoder.input_proj.3.norm.running_mean', 'decoder.input_proj.3.norm.running_var', 'decoder.input_proj.3.norm.num_batches_tracked', 'encoder.input_proj.3.conv.weight', 'encoder.input_proj.3.norm.weight', 'encoder.input_proj.3.norm.bias', 'encoder.input_proj.3.norm.running_mean', 'encoder.input_proj.3.norm.running_var', 'encoder.input_proj.3.norm.num_batches_tracked', 'encoder.lateral_convs.2.conv.weight', 'encoder.lateral_convs.2.norm.weight', 'encoder.lateral_convs.2.norm.bias', 'encoder.lateral_convs.2.norm.running_mean', 'encoder.lateral_convs.2.norm.running_var', 'encoder.lateral_convs.2.norm.num_batches_tracked', 'encoder.fpn_blocks.2.conv1.conv.weight', 'encoder.fpn_blocks.2.conv1.norm.weight', 'encoder.fpn_blocks.2.conv1.norm.bias', 'encoder.fpn_blocks.2.conv1.norm.running_mean', 'encoder.fpn_blocks.2.conv1.norm.running_var', 'encoder.fpn_blocks.2.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.2.conv2.conv.weight', 'encoder.fpn_blocks.2.conv2.norm.weight', 'encoder.fpn_blocks.2.conv2.norm.bias', 'encoder.fpn_blocks.2.conv2.norm.running_mean', 'encoder.fpn_blocks.2.conv2.norm.running_var', 'encoder.fpn_blocks.2.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.2.bottlenecks.0.conv1.conv.weight', 'encoder.fpn_blocks.2.bottlenecks.0.conv1.norm.weight', 'encoder.fpn_blocks.2.bottlenecks.0.conv1.norm.bias', 'encoder.fpn_blocks.2.bottlenecks.0.conv1.norm.running_mean', 'encoder.fpn_blocks.2.bottlenecks.0.conv1.norm.running_var', 'encoder.fpn_blocks.2.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.2.bottlenecks.0.conv2.conv.weight', 'encoder.fpn_blocks.2.bottlenecks.0.conv2.norm.weight', 'encoder.fpn_blocks.2.bottlenecks.0.conv2.norm.bias', 'encoder.fpn_blocks.2.bottlenecks.0.conv2.norm.running_mean', 'encoder.fpn_blocks.2.bottlenecks.0.conv2.norm.running_var', 'encoder.fpn_blocks.2.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.2.bottlenecks.1.conv1.conv.weight', 'encoder.fpn_blocks.2.bottlenecks.1.conv1.norm.weight', 'encoder.fpn_blocks.2.bottlenecks.1.conv1.norm.bias', 'encoder.fpn_blocks.2.bottlenecks.1.conv1.norm.running_mean', 'encoder.fpn_blocks.2.bottlenecks.1.conv1.norm.running_var', 'encoder.fpn_blocks.2.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.2.bottlenecks.1.conv2.conv.weight', 'encoder.fpn_blocks.2.bottlenecks.1.conv2.norm.weight', 'encoder.fpn_blocks.2.bottlenecks.1.conv2.norm.bias', 'encoder.fpn_blocks.2.bottlenecks.1.conv2.norm.running_mean', 'encoder.fpn_blocks.2.bottlenecks.1.conv2.norm.running_var', 'encoder.fpn_blocks.2.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.2.bottlenecks.2.conv1.conv.weight', 'encoder.fpn_blocks.2.bottlenecks.2.conv1.norm.weight', 'encoder.fpn_blocks.2.bottlenecks.2.conv1.norm.bias', 'encoder.fpn_blocks.2.bottlenecks.2.conv1.norm.running_mean', 'encoder.fpn_blocks.2.bottlenecks.2.conv1.norm.running_var', 'encoder.fpn_blocks.2.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.2.bottlenecks.2.conv2.conv.weight', 'encoder.fpn_blocks.2.bottlenecks.2.conv2.norm.weight', 'encoder.fpn_blocks.2.bottlenecks.2.conv2.norm.bias', 'encoder.fpn_blocks.2.bottlenecks.2.conv2.norm.running_mean', 'encoder.fpn_blocks.2.bottlenecks.2.conv2.norm.running_var', 'encoder.fpn_blocks.2.bottlenecks.2.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.2.conv3.conv.weight', 'encoder.fpn_blocks.2.conv3.norm.weight', 'encoder.fpn_blocks.2.conv3.norm.bias', 'encoder.fpn_blocks.2.conv3.norm.running_mean', 'encoder.fpn_blocks.2.conv3.norm.running_var', 'encoder.fpn_blocks.2.conv3.norm.num_batches_tracked', 'encoder.downsample_convs.2.conv.weight', 'encoder.downsample_convs.2.norm.weight', 'encoder.downsample_convs.2.norm.bias', 'encoder.downsample_convs.2.norm.running_mean', 'encoder.downsample_convs.2.norm.running_var', 'encoder.downsample_convs.2.norm.num_batches_tracked', 'encoder.pan_blocks.2.conv1.conv.weight', 'encoder.pan_blocks.2.conv1.norm.weight', 'encoder.pan_blocks.2.conv1.norm.bias', 'encoder.pan_blocks.2.conv1.norm.running_mean', 'encoder.pan_blocks.2.conv1.norm.running_var', 'encoder.pan_blocks.2.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.2.conv2.conv.weight', 'encoder.pan_blocks.2.conv2.norm.weight', 'encoder.pan_blocks.2.conv2.norm.bias', 'encoder.pan_blocks.2.conv2.norm.running_mean', 'encoder.pan_blocks.2.conv2.norm.running_var', 'encoder.pan_blocks.2.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.2.bottlenecks.0.conv1.conv.weight', 'encoder.pan_blocks.2.bottlenecks.0.conv1.norm.weight', 'encoder.pan_blocks.2.bottlenecks.0.conv1.norm.bias', 'encoder.pan_blocks.2.bottlenecks.0.conv1.norm.running_mean', 'encoder.pan_blocks.2.bottlenecks.0.conv1.norm.running_var', 'encoder.pan_blocks.2.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.2.bottlenecks.0.conv2.conv.weight', 'encoder.pan_blocks.2.bottlenecks.0.conv2.norm.weight', 'encoder.pan_blocks.2.bottlenecks.0.conv2.norm.bias', 'encoder.pan_blocks.2.bottlenecks.0.conv2.norm.running_mean', 'encoder.pan_blocks.2.bottlenecks.0.conv2.norm.running_var', 'encoder.pan_blocks.2.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.2.bottlenecks.1.conv1.conv.weight', 'encoder.pan_blocks.2.bottlenecks.1.conv1.norm.weight', 'encoder.pan_blocks.2.bottlenecks.1.conv1.norm.bias', 'encoder.pan_blocks.2.bottlenecks.1.conv1.norm.running_mean', 'encoder.pan_blocks.2.bottlenecks.1.conv1.norm.running_var', 'encoder.pan_blocks.2.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.2.bottlenecks.1.conv2.conv.weight', 'encoder.pan_blocks.2.bottlenecks.1.conv2.norm.weight', 'encoder.pan_blocks.2.bottlenecks.1.conv2.norm.bias', 'encoder.pan_blocks.2.bottlenecks.1.conv2.norm.running_mean', 'encoder.pan_blocks.2.bottlenecks.1.conv2.norm.running_var', 'encoder.pan_blocks.2.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.2.bottlenecks.2.conv1.conv.weight', 'encoder.pan_blocks.2.bottlenecks.2.conv1.norm.weight', 'encoder.pan_blocks.2.bottlenecks.2.conv1.norm.bias', 'encoder.pan_blocks.2.bottlenecks.2.conv1.norm.running_mean', 'encoder.pan_blocks.2.bottlenecks.2.conv1.norm.running_var', 'encoder.pan_blocks.2.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.2.bottlenecks.2.conv2.conv.weight', 'encoder.pan_blocks.2.bottlenecks.2.conv2.norm.weight', 'encoder.pan_blocks.2.bottlenecks.2.conv2.norm.bias', 'encoder.pan_blocks.2.bottlenecks.2.conv2.norm.running_mean', 'encoder.pan_blocks.2.bottlenecks.2.conv2.norm.running_var', 'encoder.pan_blocks.2.bottlenecks.2.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.2.conv3.conv.weight', 'encoder.pan_blocks.2.conv3.norm.weight', 'encoder.pan_blocks.2.conv3.norm.bias', 'encoder.pan_blocks.2.conv3.norm.running_mean', 'encoder.pan_blocks.2.conv3.norm.running_var', 'encoder.pan_blocks.2.conv3.norm.num_batches_tracked'], 'unmatched': ['decoder.anchors', 'decoder.valid_mask', 'decoder.decoder.layers.0.cross_attn.num_points_scale', 'decoder.decoder.layers.0.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.0.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.0.cross_attn.attention_weights.weight', 'decoder.decoder.layers.0.cross_attn.attention_weights.bias', 'decoder.decoder.layers.1.cross_attn.num_points_scale', 'decoder.decoder.layers.1.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.1.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.1.cross_attn.attention_weights.weight', 'decoder.decoder.layers.1.cross_attn.attention_weights.bias', 'decoder.decoder.layers.2.cross_attn.num_points_scale', 'decoder.decoder.layers.2.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.2.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.2.cross_attn.attention_weights.weight', 'decoder.decoder.layers.2.cross_attn.attention_weights.bias', 'decoder.denoising_class_embed.weight', 'decoder.enc_score_head.weight', 'decoder.enc_score_head.bias', 'decoder.dec_score_head.0.weight', 'decoder.dec_score_head.0.bias', 'decoder.dec_score_head.1.weight', 'decoder.dec_score_head.1.bias', 'decoder.dec_score_head.2.weight', 'decoder.dec_score_head.2.bias', 'encoder.input_proj.0.conv.weight', 'encoder.input_proj.1.conv.weight', 'encoder.input_proj.2.conv.weight']}
Initial lr: [0.0001, 0.0001]
building train_dataloader with batch_size=4...
Loading annotations into memory...
Done (t=0.27s)
Creating index...
index created!
building val_dataloader with batch_size=4...
Loading annotations into memory...
Done (t=0.07s)
Creating index...
index created!
number of trainable parameters: 22212212
Epoch:  10
Epoch: [0]  [   0/1609]  eta: 2:20:21  lr: 0.000000  loss: 25.4206 (25.4206)  loss_vfl: 0.8936 (0.8936)  loss_bbox: 1.1234 (1.1234)  loss_giou: 1.4776 (1.4776)  loss_vfl_aux_0: 1.5381 (1.5381)  loss_bbox_aux_0: 0.8113 (0.8113)  loss_giou_aux_0: 0.9890 (0.9890)  loss_vfl_aux_1: 1.4873 (1.4873)  loss_bbox_aux_1: 0.8079 (0.8079)  loss_giou_aux_1: 0.9985 (0.9985)  loss_vfl_dn_0: 0.7246 (0.7246)  loss_bbox_dn_0: 1.6785 (1.6785)  loss_giou_dn_0: 1.5028 (1.5028)  loss_vfl_dn_1: 0.5298 (0.5298)  loss_bbox_dn_1: 1.7747 (1.7747)  loss_giou_dn_1: 1.6161 (1.6161)  loss_vfl_dn_2: 0.4250 (0.4250)  loss_bbox_dn_2: 1.9718 (1.9718)  loss_giou_dn_2: 1.8180 (1.8180)  loss_vfl_enc_0: 1.6768 (1.6768)  loss_bbox_enc_0: 0.7680 (0.7680)  loss_giou_enc_0: 0.8077 (0.8077)  time: 5.2340  data: 1.6370  max mem: 4013
W1210 01:15:18.977000 140067784647104 torch/distributed/elastic/agent/server/api.py:741] Received Signals.SIGHUP death signal, shutting down workers
W1210 01:15:18.993000 140067784647104 torch/distributed/elastic/multiprocessing/api.py:906] Sending process 35400 closing signal SIGHUP
